{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import vgg19\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66ae5b",
   "metadata": {},
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 1e-4\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "HR = 96\n",
    "LR = HR // 4\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b4aa8",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e4b80",
   "metadata": {},
   "source": [
    "### Convolution Block(Conv -> BN -> PReLU/Element-wise Sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, discriminator = False, use_activation = True, use_bn = True, **kwargs):\n",
    "    super().__init__()\n",
    "    self.use_activation = use_activation\n",
    "    self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias = not use_bn)\n",
    "    if(use_bn == True):\n",
    "      self.bn = nn.BatchNorm2d(out_channels)\n",
    "    else:\n",
    "      self.bn = nn.Identity()\n",
    "    \n",
    "    if(discriminator == True):\n",
    "      self.act = nn.LeakyReLU(0.2, inplace = True)\n",
    "    else:\n",
    "      self.act = nn.PReLU(num_parameters = out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.cnn(x)\n",
    "    out = self.bn(out)\n",
    "    if( self.use_activation == True):\n",
    "      out = self.act(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b289fb70",
   "metadata": {},
   "source": [
    "### Upsample Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dceffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upsampleBlock(nn.Module):\n",
    "  def __init__(self, in_channels, scale_factor):\n",
    "    super().__init__()\n",
    "    self.cnn = nn.Conv2d(in_channels, in_channels * scale_factor ** 2, kernel_size = 3, stride = 1, padding = 1)\n",
    "    self.ps = nn.PixelShuffle(scale_factor)   # in_channel*4,H,W --> in_channel,2H,2W\n",
    "    self.act = nn.PReLU(num_parameters = in_channels)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.cnn(x)\n",
    "    out = self.ps(out)\n",
    "    out = self.act(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f18e6a",
   "metadata": {},
   "source": [
    "### Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class residualBlock(nn.Module):\n",
    "  def __init__(self, in_channels):\n",
    "    super().__init__()\n",
    "    self.block1 = convBlock(in_channels, in_channels, kernel_size = 3, stride = 1, padding = 1)\n",
    "    self.block2 = convBlock(in_channels, in_channels, kernel_size = 3, stride = 1, padding = 1, use_activation = False)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.block1(x)\n",
    "    out = self.block2(out)\n",
    "    return out + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b268e1f",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "  def __init__(self, in_channels = 3, num_channels = 64, num_blocks = 16):  #num_blocks = B\n",
    "    super().__init__()\n",
    "    \n",
    "    # Without BN\n",
    "    self.initial_conv = convBlock(in_channels, num_channels, kernel_size = 9, stride = 1, padding = 4, use_bn = False)\n",
    "    \n",
    "    # B = 16 Residuals Block \n",
    "    self.residuals = []\n",
    "    for _ in range(num_blocks):\n",
    "      self.residuals.append(residualBlock(num_channels))\n",
    "    \n",
    "    # conv layer after residual\n",
    "    self.later_conv = convBlock(num_channels, num_channels, kernel_size = 3, stride = 1, padding = 1, use_activation = False)\n",
    "    \n",
    "    # 2 conv layer with PixelShuffler\n",
    "    self.PS_conv1 = upsampleBlock(num_channels, scale_factor = 2)\n",
    "    self.PS_conv2 = upsampleBlock(num_channels, scale_factor = 2)\n",
    "    \n",
    "    self.last_conv = nn.Conv2d(num_channels,in_channels,kernel_size = 9, stride = 1, padding = 4)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.initial_conv(x)\n",
    "    initial = copy.copy(out)\n",
    "    for i in range(len(self.residuals)):\n",
    "      out = self.residuals[i](out)\n",
    "    out = self.later_conv(out) + initial\n",
    "    print(out.shape)\n",
    "    out = self.PS_conv1(x)\n",
    "    out = self.PS_conv2(x)\n",
    "    out = self.last_conv(x)\n",
    "    out = torch.tanh(out)\n",
    "    return out   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c7420",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "  def __init__(self, in_channels, features = [64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "    super.init__()\n",
    "    self.blocks = []\n",
    "    for i, feature in enumerate(features):\n",
    "      self.blocks.append(convBlock(in_channels, feature, kernel_size = 3, stride = (1 + (i%2)), padding = 1, discriminator = True, use_act = True, use_bn = False if i == 0 else True))\n",
    "      in_channels = feature\n",
    "\n",
    "    # Final Dense Layers\n",
    "    self.final_layers = nn.Sequential(\n",
    "      nn.AdaptiveAvgPool2d((6, 6)),\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(512*6*6, 1024),\n",
    "      nn.LeakyReLU(0.2, inplace = True),\n",
    "      nn.Linear(1024, 1)\n",
    "    )\n",
    "    \n",
    "    def forward(self,x):\n",
    "      for i in range(len(self.blocks)):\n",
    "        x = blocks[i](x)\n",
    "        \n",
    "      out = final_layers(x)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ba0f3",
   "metadata": {},
   "source": [
    "## Testing Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab99167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR = 24\n",
    "# with torch.cuda.amp.autocast():\n",
    "#   x = torch.randn((5,3,LR,LR))\n",
    "#   gen = generator()\n",
    "#   gen_out = gen(x)\n",
    "#   disc = discriminator()\n",
    "#   disc_out = disc(gen_out)\n",
    "  \n",
    "#   print(gen_out.shape)\n",
    "#   print(disc_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59611793",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90166fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi_5,4: 5th conv layer before maxpooling but after activation\n",
    "class VGG19Loss(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.vgg = vgg19(pretrained = True).features[:36].eval().to(config.DEVICE)\n",
    "    self.loss = nn.MSELoss()\n",
    "    \n",
    "    for param in self.vgg.parameters():\n",
    "      param.requires_grad = False\n",
    "      \n",
    "  def forward(self, input, target):\n",
    "    vgg_input_features = self.vgg(input)\n",
    "    vgg_target_features self.vgg(target)\n",
    "    loss = self.loss(vgg_input_features, vgg_target_features)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c1349",
   "metadata": {},
   "source": [
    "### Function to transform images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbeaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "highres_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lowres_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_transforms = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e32f3c",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee38a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImageFolder(Dataset):\n",
    "  def __init__(self, root_dir):\n",
    "    super(MyImageFolder, self).__init__()\n",
    "    self.data = []\n",
    "    self.root_dir = root_dir\n",
    "    self.class_names = os.listdir(root_dir)\n",
    "\n",
    "    for index, name in enumerate(self.class_names):\n",
    "      files = os.listdir(os.path.join(root_dir, name))\n",
    "      self.data += list(zip(files, [index] * len(files)))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_file, label = self.data[index]\n",
    "    root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n",
    "\n",
    "    image = np.array(Image.open(os.path.join(root_and_dir, img_file)))\n",
    "    image = both_transforms(image=image)[\"image\"]\n",
    "    high_res = highres_transform(image=image)[\"image\"]\n",
    "    low_res = lowres_transform(image=image)[\"image\"]\n",
    "    return low_res, high_res\n",
    "\n",
    "train_dataset = MyImageFolder(root_dir=\"trainData/\")\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75116b",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a34028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss):\n",
    "  loop = tqdm(loader, leave=True)\n",
    "\n",
    "  for idx, (low_res, high_res) in enumerate(loop):\n",
    "    high_res = high_res.to(device)\n",
    "    low_res = low_res.to(device)\n",
    "\n",
    "    ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "    fake = gen(low_res)\n",
    "    disc_real = disc(high_res)\n",
    "    disc_fake = disc(fake.detach())\n",
    "    disc_loss_real = bce(\n",
    "        disc_real, torch.ones_like(disc_real) - 0.1 * torch.rand_like(disc_real)\n",
    "    )\n",
    "    disc_loss_fake = bce(disc_fake, torch.zeros_like(disc_fake))\n",
    "    loss_disc = disc_loss_fake + disc_loss_real\n",
    "\n",
    "    opt_disc.zero_grad()\n",
    "    loss_disc.backward()\n",
    "    opt_disc.step()\n",
    "\n",
    "    # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "    disc_fake = disc(fake)\n",
    "    #l2_loss = mse(fake, high_res)\n",
    "    adversarial_loss = 1e-3 * bce(disc_fake, torch.ones_like(disc_fake))\n",
    "    loss_for_vgg = 0.006 * vgg_loss(fake, high_res)\n",
    "    gen_loss = loss_for_vgg + adversarial_loss\n",
    "\n",
    "    opt_gen.zero_grad()\n",
    "    gen_loss.backward()\n",
    "    opt_gen.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf34a49",
   "metadata": {},
   "source": [
    "### Training Starts Here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03380b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator(in_channels=num_channels).to(device)\n",
    "disc = discriminator(img_channels=num_channels).to(device)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "mse = nn.MSELoss()\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "vgg_loss = VGGLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_fn(train_data_loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16e3ea",
   "metadata": {},
   "source": [
    "### Testing Models here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_SR(lr_folder, gen):\n",
    "  files = os.listdir(lr_folder)\n",
    "\n",
    "  gen.eval()\n",
    "  for file in files:\n",
    "    image = Image.open(lr_folder + \"/\" + file)\n",
    "    with torch.no_grad():\n",
    "      upscaled_img = gen(test_transform(image=np.asarray(image))[\"image\"].unsqueeze(0).to(device))\n",
    "    save_image(upscaled_img * 0.5 + 0.5, f\"saved/{file}\")\n",
    "  gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45273507",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_SR(\"testData\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
